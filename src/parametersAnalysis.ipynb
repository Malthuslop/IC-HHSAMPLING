{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/haphazard/.local/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in /home/haphazard/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: seaborn in /home/haphazard/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: pyswarms in /home/haphazard/.local/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.5.1)\n",
      "Requirement already satisfied: statsmodels in /home/haphazard/.local/lib/python3.10/site-packages (0.14.1)\n",
      "Requirement already satisfied: pygad in /home/haphazard/.local/lib/python3.10/site-packages (3.3.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/haphazard/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/haphazard/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: future in /usr/lib/python3/dist-packages (from pyswarms) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /home/haphazard/.local/lib/python3.10/site-packages (from pyswarms) (4.66.2)\n",
      "Requirement already satisfied: attrs in /usr/lib/python3/dist-packages (from pyswarms) (21.2.0)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from pyswarms) (5.4.1)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from pyswarms) (1.8.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /home/haphazard/.local/lib/python3.10/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/lib/python3/dist-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: cloudpickle in /home/haphazard/.local/lib/python3.10/site-packages (from pygad) (3.0.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install pandas numpy seaborn pyswarms matplotlib statsmodels pygad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hhsolver import *\n",
    "from PIL import Image\n",
    "from utils import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from hhsampling_params import *\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/Candidatos20230803_n.txt'\n",
    "data = collect_data(file_path=file_path).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_n = 0#, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "\n",
    "nalloc = 100\n",
    "\n",
    "sample_size_list = [60, 120, 180, 240] #4\n",
    "time_limit_list = [120]#[5,10,20,30,60,120]#,240] #7\n",
    "particles_number_list = [25,50,100]#,150,200] #5\n",
    "c1_list = [0.0001, 0.1,1, 10, 100, 1000, 10000] #7\n",
    "c2_list = [0.0001, 0.1, 1, 10, 100, 1000, 10000] #7\n",
    "w_list = [0.0001, 0.1, 1, 10, 100, 1000, 10000] #7\n",
    "\n",
    "# hhsamplingGA require transformed data\n",
    "x = data @ inversecholcov(data)\n",
    "solver = HHSolverPSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"sample size\", \"time limit\", \"particles number\", \"cognitive param\", \"social param\", \"allocation number\", \"fitness score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haphazard/.local/lib/python3.10/site-packages/pyswarms/backend/operators.py:143: RuntimeWarning: overflow encountered in multiply\n",
      "  temp_velocity = (w * swarm.velocity) + cognitive + social\n",
      "/home/haphazard/.local/lib/python3.10/site-packages/pyswarms/discrete/binary.py:282: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "with open('PSO_dataframe001.csv', 'w', newline='') as arquivo_csv:\n",
    "    escritor = csv.writer(arquivo_csv)\n",
    "    escritor.writerow([\"sample size\", \"time limit\", \"particles number\", \"cognitive param\", \"social param\", \"weight\", \"allocation number\", \"fitness score\"])\n",
    "    for sample_size in sample_size_list:\n",
    "        for time_limit in time_limit_list:\n",
    "            for particles_number in particles_number_list:\n",
    "                for c1 in c1_list:\n",
    "                    for c2 in c2_list:\n",
    "                        for w in w_list:\n",
    "                            # pre-generate noises used in each batch\n",
    "                            ma = 2\n",
    "                            noise = []\n",
    "                            populations = []\n",
    "                            for i in range(nalloc):\n",
    "                                z = generate_noise(x.shape[0], ma)\n",
    "                                # hhsamplingGA require transformed noise\n",
    "                                zt = z @ inversecholcov(z)\n",
    "                                noise.append(zt)\n",
    "                                populations.append(generate_pop(particles_number, sample_size, x.shape[0]))\n",
    "\n",
    "\n",
    "                            dist = hhsampling(x, lambda_n, nalloc, sample_size, noise, populations, solver, time_limit, particles_number, c1, c2, w)\n",
    "                            for j in range(nalloc):\n",
    "                                    #[\"sample size\", \"time limit\", \"particles number\", \"cognitive param\", \"social param\", \"allocation number\", \"fitness score\"])\n",
    "                                    escritor.writerow([sample_size, time_limit, particles_number, c1, c2, w, j, dist[j]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.append(newRows, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df, x = df.iloc[:,2], y = df.iloc[:,6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
